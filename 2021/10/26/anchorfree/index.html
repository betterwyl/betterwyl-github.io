<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Yulin,Wang"><title>Anchor-free系列 · Yulin Wang</title><meta name="description" content="CornerNet 2个角点：左上角和右下角角点input：image经过一个ConvNet→生成feature maphourglass network: 捕获图片在多个尺度下的特征。1、降采样操作缩小输入的大小；2、上采样恢复到输入图像大小常用：使用多个pipeline分别单独处理不同尺度下的信"><meta name="keywords" content="Recording"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:130px;" alt="favicon"><h3 title=""><a href="/">Yulin Wang</a></h3><div class="description"><p>The man is lazy, nothing left.</p></div></div></div></div><ul class="social-links"><li><a href="https://github.com/betterwyl" target="_blank" rel="noopener"><i class="fa fa-github"></i></a></li><li><a href="yulinwang@mail.ustc.edu.cn"><i class="fa fa-envelope"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2020 </span><i class="fa fa-star"></i><span> Yulin,Wang</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div></div></div><div class="page-top animated fadeInDown"><div class="nav"><li> <a href="/">Article List</a></li><li> <a href="/about">About me</a></li><li> <a href="/archives">Repository</a></li><li> <a href="/tags">Tags List</a></li><li> <a href="/guestbook">Guest book</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Anchor-free系列</a></h3></div><div class="post-content"><h2 id="CornerNet-2个角点：左上角和右下角角点"><a href="#CornerNet-2个角点：左上角和右下角角点" class="headerlink" title="CornerNet 2个角点：左上角和右下角角点"></a>CornerNet 2个角点：左上角和右下角角点</h2><p>input：image经过一个ConvNet→生成feature map<br>hourglass network: 捕获图片在多个尺度下的特征。1、降采样操作缩小输入的大小；2、上采样恢复到输入图像大小<br>常用：使用多个pipeline分别单独处理不同尺度下的信息，网络的后面部分再组合这些特征。<br>上面分支module负责预测左上角corner，下面分支module负责预测右下角corner<br>需要group操作。<br>heatmaps预测：Corners点概率；<br>中心点不一定局限在某一个位置上 而是一个区域→中心点落在半径r范围内设置一个iou→圆圈内的点的数值是以圆心往外呈二维的高斯分布；【对不同负样本点的损失函数采取不同权重值的原因：白色虚线是一个预测框，预测框的两个角点和ground truth并不重合，但是该预测框大概框住了目标，因此是有用的预测框，所以要有一定权重的损失返回】<br>loss：带有惩罚因子的Focal loss 降低接近真值损失 进一步解决样本不均衡<br>embeddings预测：解决的是配对问题：一个目标的两个角点，二者的embedding vector之间的距离应该很小。每个点所属的目标中心点；采用L1范数，距离大于0.5或者两个点来自不同类别的目标的都不能构成一对。<br>offsets：表示在取整计算时丢失的精度信息，输入图像到特征图之间会有尺寸缩小。anchor-based方法是算和anchor偏移。针对小尺寸目标的回归。这是针对角点的。</p>
<p>corner pooling：怎么知道这个点就是角点？特征点肯定是最大的。红色的部分。找到值最大的网格然后确保该网格左边的网格全部都能变成最大值，也就是把水平方向最明显的特征向左延续；竖直方向最明显的特征向上延续；这样当两幅heatmap相加时→两者最明显特征的路线相重叠，这样加出来的值肯定也是最大的，因此就能推测出左上角关键点的位置。</p>
<p>测试：<br>在得到预测角点后，会对这些角点做NMS操作，选择前100个左上角角点和100个右下角角点。测试图像采用0值填充方式得到指定大小作为网络的输入，而不是采用resize，另外同时测试图像的水平翻转图并融合二者的结果。最后通过soft-nms操作去除冗余框，只保留前100个预测框</p>
<h2 id="ExtremeNet"><a href="#ExtremeNet" class="headerlink" title="ExtremeNet"></a>ExtremeNet</h2><p>检测目标的4个极值点（即最上点、最下点、最左点、最右点）和一个中心点<br>需要group操作。针对CornerNet预测的角点经常落在目标外部，没有足够的目标特征改进。<br>backbone：Hourglass Network<br>heatmap：*5 4个极值点+1个中心点。<br>根据顶、底、左、右四个点集，从四个点集中各抽取一个得到四个极值，计算几何中心坐标，找到该中心坐标在中心点heatmap中的得分，如果高于阈值，那么这四个极值点组成的bounding box返回一个最终得分→五个点得分的平均值。<br>Ghost box抑制：解决比如要找2的中心，有可能找的是更大的这个框而不是2的box。如果box，其里面所有的包围框的得分超过了其本身得分的3倍→修正为原来的1/2</p>
<p>Edge aggregation：解决极值点不唯一问题。对于左边右边极值点在竖直方向聚合；顶部底部极值点在水平方向聚合。【沿着聚合方向，将第一个单调下降区间内的点的score按一定权重累加到原极值点上，并在达到局部最小值的时候停止聚合】</p>
<h2 id="Objects-as-Points【Centernet】"><a href="#Objects-as-Points【Centernet】" class="headerlink" title="Objects as Points【Centernet】"></a>Objects as Points【Centernet】</h2><p>只预测中心点。通过检测物体的中心点以及中心点对应的w,h来实现检测。不需要group操作<br>input：512<br>backbone: DLA 沙漏型<br>hourglass network 姿态检测<br>output：fm128 降了4倍 → 三个head<br>三个head：<br>1、    heatmap【功能是预测中心点】：128<em>128</em>class；同CornerNet<br>关于高斯圆的半径确定，iou overlap 情况讨论：三种情况的半径，预测的全覆盖；gt全覆盖；交错 overlap=0.7作为临界值，取最小值作为高斯核的半径R。<br>2、128<em>128</em>2；【对应location宽、高】使用L1<br>3、28<em>128</em>2；【中心点：细化调整 offset  x y】引入偏置的损失值，降4倍后取证会带来误差。<br>o是预测的偏移值数量 R表示Heatmap的缩放因子 p~是缩放后取证的坐标</p>
<p>为什么没有给每个类别预测宽高？考虑物体中心点不会重合<br>3D目标检测：<br>1、depth不好直接回归； 在特征点估计网络上添加了一个深度计算通道，L1 loss。参考文章：Depth map prediction from a single image using a multi-scale deep network.<br>2、l w h L1 loss<br>3、方向也很难回归；用两个bins来呈现方向→方向用8个标量值来编码的形式，每个bin有4个值。对于一个bin，两个值用作softmax分类，其余两个值回归到在每个bin中的角度。参考文章：3d bounding box estimation using deep learning and geometry.√</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2021-10-26</span><i class="fa fa-tag"></i><a class="tag" href="/tags/学习记录【目标检测】/" title="学习记录【目标检测】">学习记录【目标检测】 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://betterwyl.github.io/2021/10/26/anchorfree/,Yulin Wang,Anchor-free系列,;" target="_blank" rel="noopener"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2021/11/17/R-CNN%E7%B3%BB%E5%88%97/" title="R-CNN系列 （实习摸鱼中）">Previous</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2021/10/10/backbone%E8%80%95%E8%80%98%E7%89%88/" title="backbone挖坑中">Next</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'xHB6JST92sP5ORC9WNZ7DwXX-gzGzoHsz',
  app_key:'cqHNrhvssKtJ6KzZLln1xtVv',
  placeholder:'...',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'mp'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>