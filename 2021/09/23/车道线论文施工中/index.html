<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Yulin,Wang"><title>车道线论文阅读 （施工多年版本） · Betterwyl</title><meta name="description" content="英东师兄给发了一大堆车道线论文。
基于语义分割的方法
SCNN将传统的卷积层接层的连接形式的转为feature map中片连片卷积的形式。创新点：适用于检测长距离连续形状的目标或大型目标，有着极强的空间关系但是外观线索较差的目标，例如交通线，电线杆和墙。空间信息能在卷积层上传播。【feature m"><meta name="keywords" content="Recording"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 4.2.1"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:200px;"><h3 title=""><a href="/">Betterwyl</a></h3><div class="description"><p>The man is lazy, nothing left.  /  review&query</p></div></div></div><ul class="social-links"><li><a href="https://github.com/betterwyl" target="_blank" rel="noopener"><i class="fa fa-github"></i></a></li><li><a href="yulinwang@mail.ustc.edu.cn"><i class="fa fa-envelope"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2020 </span><i class="fa fa-star"></i><span> Yulin,Wang</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><a href="https://github.com/mrcore/hexo-theme-Anatole-Core" target="_blank">Anatole-Core  </a></div><div class="beian"><a href="http://www.beian.miit.gov.cn/" target="_blank"></a><span style="height:10px;margin-left: 10px;">|</span><img src="/images/gongan.png" style="height:10px;margin-left: 10px;position: relative;top: 1px;"><span style="margin-left: 2px;"></span></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><li><a href="/guestbook">留言</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>车道线论文阅读 （施工多年版本）</a></h3></div><div class="post-content"><p>英东师兄给发了一大堆车道线论文。</p>
<p>基于语义分割的方法</p>
<h2 id="SCNN"><a href="#SCNN" class="headerlink" title="SCNN"></a>SCNN</h2><p>将传统的卷积层接层的连接形式的转为feature map中片连片卷积的形式。<br>创新点：适用于检测长距离连续形状的目标或大型目标，有着极强的空间关系但是外观线索较差的目标，例如交通线，电线杆和墙。<br>空间信息能在卷积层上传播。【feature map的行或列也看成layer，也使用卷积加非线性激活，从而实现空间上的深度神经网络。】<br>数据集：CULane Dataset 提出<br><a href="https://xingangpan.github.io/projects/CULane.html" target="_blank" rel="noopener">https://xingangpan.github.io/projects/CULane.html</a><br>没有包括一些车道线模糊，条件恶劣的情况，而这些情况人类可以推断出来，且这具有很高的实用价值。<br>每张图使用3条注释。<br>*传统的关于空间关系的建模方法是基于概率图模型的，例如马尔科夫随机场(MRF)或条件随机场(CRF)。【要去了解一下】<br>D、U、R、L是四个信息传递模块。D、U沿着H方向做了从上到下和从下到上的信息传递；R、L沿着W方向做了从左到右和从右到左的信息传递。每一个模块的卷积函数都共享同一个卷积核。</p>
<p>MRF/CRF中每个像素点会直接接收其他所有像素点的信息(大卷积核实现)，这其中有许多冗余计算；而SCNN在信息传递顺序传递，由此简化了信息传递的结构加快了模型的运算效率。</p>
<p>output：加入一个分支网络。【这个分支网络能够直接区分不同车道标记，这样鲁棒性更好。共有4中类型的车道线。输出的概率图经过这个分支网络预测车道标记是否存在。】</p>
<h2 id="SAD【开源-语义分割-知识蒸馏】"><a href="#SAD【开源-语义分割-知识蒸馏】" class="headerlink" title="SAD【开源/语义分割+知识蒸馏】"></a>SAD【开源/语义分割+知识蒸馏】</h2><p>提出基于知识蒸馏的车道线检测模型SAD，允许车道检测网络在不需要额外标签和外部监督的情况下加强自身的表征学习。增强CNN的特征表达能力。SAD只参与模型训练，因此不会增加推断时的计算复杂度。<br>*知识蒸馏补充（模型压缩）：<br>Net-T完整地学习Ground Truth →由Net-S同时学习Net-T的Logit和Ground Truth，最终Net-S作为应用模型，而Net-T并不进行部署上线。<br>Logit：模型输出的对于各个类别的概率预测值<br>Ground Truth：真值<br>hard target 包含的信息量（信息熵）很低【类似于one-hot，有一个特别突出】，soft target包含的信息量大，拥有不同类之间关系的信息。<br>    更改损失函数→Net-S两部分的知识——<br>Loss-soft：Net-S的输出和Net-T的分布差异。带有T的目标。<br>Loss-hard：GroundTruth的分布差异，可理解为就是正常的分类，有明确的答案。<br>论文中说：第一个目标函数的权重要大一些<br> q是Net-S的输出，p是Net-T的输出，c是Ground Truth</p>
<p>q和p要用softmax-T公式：<br> →<br>【T=1就是softmax。T参数是一个温度超参数，按照softmax的分布来看，随着T参数的增大，这个软目标的分布更加均匀（平缓）。】</p>
<p>知识蒸馏图解<br>1 训练大模型：先用hard target，也就是正常的label训练大模型。<br>eg. T-Net：对softmax（T=1）的输出与原始label求loss2<br>2 计算soft target：利用训练好的T-Net大模型来计算soft target（也就是大模型“软化后”再经过softmax的output），再加一个额外的S-Net的soft target。<br>eg.对Teacher的softmax（T=20）输出＋softmax（T=20）的输出=loss1。<br>3 训练小模型，通过lambda来调节两个loss functions的比重。<br>loss = loss1+loss2<br>4 预测：将训练好的小模型按常规方式使用。<br>　　　　　　　<br>创新点：<br>首次使用网络自身的注意力地图作为蒸馏目标。<br>第一次尝试使用网络自身的注意力地图作为蒸馏目标。<br>语义分割任务→通过层间的信息流动，使网络可以在深层保留场景的上下文信息。该算法的这一特性刚好匹配车道线检测任务的特点，即车道线长且窄的形态</p>
<h2 id="CurveLane-NAS【弯道车道线检测】"><a href="#CurveLane-NAS【弯道车道线检测】" class="headerlink" title="CurveLane-NAS【弯道车道线检测】"></a>CurveLane-NAS【弯道车道线检测】</h2><p>Unifying Lane-Sensitive Architecture Search and Adaptive Point Blending华为诺亚方舟实验室<br>AutoML链→<a href="https://github.com/huawei-noah/vega【新东西的使用？】" target="_blank" rel="noopener">https://github.com/huawei-noah/vega【新东西的使用？】</a><br>从网络搜索的角度，针对长条形车道线，捕捉车道线全局的连贯性特征和局部的弯曲特征。<br>Elastic Backbone Search Module，有效提取车道线的语义特征和隐藏特征；<br>Feature Fusion Search Module，充分融合不同尺度的全局和局部特征；<br>Adaptive Point Blending Search Module，一种多尺度后处理策略，根据不同尺度的预测结果，得到一个更为准确的车道线检测结果。</p>
<p>数据集：CurveLanes华为发布的CurveLanes数据集中90%以上都是曲线车道，约包含13万5000张图像（共15万张图像）数据集有100k训练图片，仅标注了车道线形状，未标注车道线类型。<br>*NAS补充：（网络结构搜索）简单来讲就是定义网络结构参数的自动调优</p>
<p>基于分类方法</p>
<h2 id="Ultra-Fast-Structure-aware-Deep-Lane-Detection-【开源】"><a href="#Ultra-Fast-Structure-aware-Deep-Lane-Detection-【开源】" class="headerlink" title="Ultra Fast Structure-aware Deep Lane Detection 【开源】"></a>Ultra Fast Structure-aware Deep Lane Detection 【开源】</h2><p>这篇文章从分类的角度来构思车道线检测这个问题。（行分类）<br>提出了基于row anchor的网络【最后面增加1个空cell，这个cell表示该row anchor中没有车道线】，让网络在不同的行中选择属于车道线的列，减少了传统语义分割pixel level prediction的复杂度，同时使用global feature来增加网络的感受野， 提升在有车辆遮挡关系下的网络推理能力。<br>*补充感受野：<br>卷积神经网络每一层输出的feature map上的像素点在输入图片上映射的区域大小。【特征图上一个点→代表原图一个区域】<br>感受野大小的计算：<br> 从前往后算 （lk,lk-1感受野大小，fk卷积核大小，s步长）<br> 从后往前算 （先计算最深层在前一层上的感受野，然后逐渐传递到第一层）<br>【计算感受野大小时，忽略了图像边缘的影响，即不考虑padding的大小】<br>eg.典型的VGG net问题—— 2个3x3的卷积核替代5x5的卷积核。<br>    创新点：<br>    提出了一种新的车道检测公式，旨在以极快的速度解决无视觉障碍问题。【与深度分割方法相比，不是分割每个像素，而是选择车道的位置。】<br>    基于提出的公式，我们提出了一种结构损失，以明确利用车道的先验信息。<br>    特点：速度快<br>具体来说，我们的公式是使用全局特征在图像的预定义行中选择车道位置，而不是基于局部感受野分割车道的每个像素，这显著降低了计算成本。<br>【借助于全局特征→具有整个图像的感受野。与基于有限感受野的分割相比，可以学习和利用来自不同位置的视觉线索和信息。】<br>它将问题转化为对图像中的特定行进行分类，每一个类别代表车道线所在的一个位置。图像行上的格网点位置。<br>    操作：<br>对原图进行一定降采样操作后【降采样到800x288】→一个Feature-map<br>    每一个channel代表一条特定的车道线；<br>    每一行对应原图中某几行组成的一个Row anchor；<br>    Row中的每一个col，对应了原图中某几列的位置，另外有一个额外的col，代表了无车道线，即背景类。<br>核心：<br>    车道检测新公式<br>input：H×W图片<br>最大车道数假设为C。<br>基于全局特征预测每行锚点上所有位置的概率分布。因此，可以根据概率分布选择正确的位置。<br> 【每一行都有一个坐标。i车道索引，对应j列。】<br>监督使用的是交叉熵的形式。P是预测T真实。</p>
<p>跑得快的原因：<br>对于文章的方法其是在特征图上进行的。特征图尺寸h×w进行的行切分之后是1<em>w的特征，进行预测之后得到 (w+1)维度的预测结果。c*h</em>(w+1)<br>分割:H<em>W</em>(C+1)<br>视觉不可见场景下的预测:<br>使用全连接的方式从而拥有了全局的视野，从而增加了对于这样场景的适应性。【有点不理解。如何通过这种方式，利用来自其他位置的信息，文中说公式具有整个图像的感受野，比分割方法大得多。从学习的角度来看，还可以使用基于我们公式的结构损失来学习车道形状和方向等先验信息】<br>另一个显著的好处是，这种公式以基于行的方式建立车道位置模型，这使我们有机会明确地建立不同行之间的关系。该方法可以弥补由低级像素化建模和高级车道长线结构造成的原有语义鸿沟。【问题如何明确地建立不同行之间的关系。】<br> 车道线的结构Loss:</p>
<p> 相邻行锚中的车道点应该彼此接近<br>【比如说第二行和第一行同一条车道线，那个小块他们接近。】<br> 车道形状——相邻行之间的朝向性应该是一致的【这边有点不解】<br>第j行，第i个车道的位置，选择预测概率最大的作为预测值。但不可导，换个形式。→使用二阶差分的形式。</p>
<p>特征聚合：<br>最后一项是分割的损失【有点不理解，文中说使用交叉熵作为辅助分割损失】<br>【复现指南：<a href="https://blog.csdn.net/weixin_46716951/article/details/112650165?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7Edefault-6.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7Edefault-6.no_search_link】" target="_blank" rel="noopener">https://blog.csdn.net/weixin_46716951/article/details/112650165?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7Edefault-6.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EOPENSEARCH%7Edefault-6.no_search_link】</a></p>
<p>基于锚点的方法</p>
<h2 id="Line-CNN代码不是公开的"><a href="#Line-CNN代码不是公开的" class="headerlink" title="Line-CNN代码不是公开的"></a>Line-CNN代码不是公开的</h2><h2 id="LaneATT-基于anchor实现，且应用了注意力机制"><a href="#LaneATT-基于anchor实现，且应用了注意力机制" class="headerlink" title="LaneATT 基于anchor实现，且应用了注意力机制"></a>LaneATT 基于anchor实现，且应用了注意力机制</h2><p>Keep your Eyes on the Lane: Real-time Attention-guided Lane Detection<br><a href="https://github.com/lucastabelini/LaneATT" target="_blank" rel="noopener">https://github.com/lucastabelini/LaneATT</a><br>LaneATT是一种基于锚的单级模型，类似YOLOv3或SSD。提出了一种新的基于锚点的聚合全局信息的注意机制。<br>*注意力机制补充<br>三种注意力域，空间域(spatial domain)，通道域(channel domain)，混合域(mixed domain)<br>通俗解释：attention机制可以它认为是一种资源分配的机制，可以理解为对于原本平均分配的资源根据attention对象的重要程度重新分配资源，重要的单位就多分一点，不重要或者不好的单位就少分一点，在深度神经网络的结构设计中，关注权重。<br>很多种类别：<br><a href="https://zhuanlan.zhihu.com/p/146130215" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/146130215</a></p>
<p>    空间域(spatial domain)<br>一般认为，卷积神经网络中的池化层（pooling layer）直接用一些max 法或者average 法的方法，将图片信息压缩，减少运算量提升准确率。【改进：直接将信息合并会导致关键信息无法识别出来，所以提出了一个叫空间转换器（spatial transformer）的模块。】<br>因为训练出的spatial transformer能够找出图片信息中需要被关注的区域，同时transformer又能够具有旋转、缩放变换的功能，这样图片局部的重要信息能够通过变换而被框盒提取出来。<br>    通道域(channel domain)<br>通道域的注意力机制原理【可以从基本的信号变换的角度去理解。信号系统分析里面，任何一个信号其实都可以写成正弦波的线性组合，经过时频变换后，时域上连续的正弦波信号就可以用一个频率信号数值代替了。】<br>eg.在卷积神经网络中每一张图片初始会由（R，G，B）三通道表示出来，之后经过不同的卷积核之后，每一个通道又会生成新的信号。<br>图片特征的每个通道使用64核卷积，就会产生64个新通道的矩阵（H,W,64），每个信号都可以被分解成核函数上的分量，产生的新的64个通道对于关键信息的贡献不定→给每个通道上的信号都增加一个权重，来代表该通道与关键信息的相关度的话，这个权重越大，则表示相关度越高，即关注的权重（注意力）。<br>方法    优缺点<br>空间域    将每个通道中的图片特征同等处理。这种做法会将空间域变换方法局限在原始图片特征提取阶段<br>通道域    对一个通道内的信息直接全局平均池化，而忽略每一个通道内的局部信息。</p>
<p>    混合【没太看明白？？？】<br>里面有一种残差注意力学习(residual attention learning)<br><a href="https://mp.weixin.qq.com/s/KKlmYOduXWqR74W03Kl-9A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/KKlmYOduXWqR74W03Kl-9A</a></p>
<p> 核心：<br>input:一幅图像→使用Resnet作为特征提取【骨干网】，生成一个特征映射→汇集起来提取每个锚的特征+与一组由注意力模块产生的全局特征相结合，通过结合局部和全局特征，这在遮挡或没有可见车道标记的情况下可以更容易地使用来自其他车道的信息。<br>主干从输入图像生成特征映射。每个锚被投影到特征图上。这个投影用于汇集与注意力模块中创建的另一组特征相连接的特征。最后，使用得到的特性集【两层，一层用于分类，另一层用于回归】组合特征传递给全连接层→预测最终的输出车道。<br>anchor用原点和方向角表示。【车道线起点的意思，出现在一张图片的左右下】<br>output: 输出车道边界线<br>对于每个anchor，网络最终输出3类信息：<br>    K+1概率（K条车道线类型和一个类别的背景）；<br>    offset：水平偏移x0，x1…（预测与锚线之间的水平距离）；<br>    车道线长度l<br> NMS：</p>
<p>xa、xb是两条车道。当两者距离小于阈值时，该anchor被当作正样本，当两者距离大于阈值时，该anchor被当作负样本。</p>
<p> Loss：</p>
<p>*补充Facal loss：【理解为用一个函数去度量难分类和易分类样本对总的损失的贡献。】<br>负样本数量太大，占总的loss的大部分，而且多是容易分类的，因此使得模型的优化方向并不是我们所希望的那样。这个函数可以通过减少易分类样本的权重，使得模型在训练时更专注于难分类的样本。<br><a href="https://blog.csdn.net/u014380165/article/details/77019084?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link" target="_blank" rel="noopener">https://blog.csdn.net/u014380165/article/details/77019084?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link</a><br>*补充 此处回归使用smooth L1</p>
<p>L1范数损失函数，也被称为最小绝对值误差。L1损失的缺点就是有折点，不光滑，导致不稳定。loss对于离群点更加鲁棒，相比于L2损失函数，其对离群点、异常值不敏感，可控制梯度的量级使训练时不容易飞。<br>L2范数损失函数，也被称为最小平方误差（LSE）。受离群点影响较大，即离群点可能放多点权重。【警惕梯度爆炸现象】<br>【启发：可以更改loss来测试性能。】<br><a href="https://blog.csdn.net/l641208111/article/details/114286443?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link" target="_blank" rel="noopener">https://blog.csdn.net/l641208111/article/details/114286443?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link</a><br>【参考复现<a href="https://blog.csdn.net/weixin_50996258/article/details/114194722】" target="_blank" rel="noopener">https://blog.csdn.net/weixin_50996258/article/details/114194722】</a></p>
<p>##3D-LaneNet: End-to-End 3D Multiple Lane Detection<br>数据集：tuSimple<br>方法：<br>网络内逆投影映射IPM + 基于anchor的车道线表示<br>一个基于CNN的端到端的3D车道线检测网络3D-LaneNet，可以直接检测多个车道，并估计车道曲率<br><em>补充：逆投影变换IPM：<br>动态逆变换主要用于自动驾驶中，安装在车辆上的相机在采集车道线图片时，原本平行的车道线将呈现出一定角度，将图片中具有一定角度的车道线恢复平行的过程，就称为动态逆投影变换。</em>此概念涉及到相机标定知识。</p>
<p>存在的解决方案：加载离线生成的预映射车道和基于感知的实时车道检测。<br>基于相机的车道检测，一般假设地面是平坦的，如果说投影到三维的坐标系中，违反假设会导致估计不准确。<br>创新性：<br>定义了3D车道线检测任务的度量标准，同时也第一个提出了3D检测任务的解决办法；<br>一种新的双路径【是指信息在两条通路中被处理，正视图和俯视图】架构，部署内部网络特征映射IPM投影？？？？<br>一种新的基于anchor的车道输出表示，使直接的、端到端训练网络，用于3D和基于图像的车道检测。【将问题归结为一个物体检测问题，其中每个车道线都是一个物体，并且其3D曲线模型的估计就像对象的边界框一样。】<br>一种随机生成具有车道拓扑变化(车道数、汇集、分叉)和三维形状的合成样本的方法。<br>模型：<br>输入：一张图（正视图） →基于双特征图image view and top view（对特征图进行一些透射投影变换以生成虚拟的鸟瞰视图）；<br>假设：相机的内参矩阵κ已知（焦距，光心）；车辆相对于路面的侧倾角为0；不知道高度和俯仰角，因为随着车辆的动力学运动，他们是会改变的。<br>输出：道路的纵向切片【避免了聚类、奇异值？？】</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2021-09-23</span><i class="fa fa-tag"></i><a class="tag" href="/tags/学习记录【车道线】/" title="学习记录【车道线】">学习记录【车道线】 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://betterwyl.github.io/2021/09/23/车道线论文施工中/,Betterwyl,车道线论文阅读 （施工多年版本）,;" target="_blank" rel="noopener"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2021/10/10/backbone%E8%80%95%E8%80%98%E7%89%88/" title="backbone挖坑中">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2021/09/10/DL%E8%B4%B4%E5%A3%AB/" title="小方法">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'xHB6JST92sP5ORC9WNZ7DwXX-gzGzoHsz',
  app_key:'cqHNrhvssKtJ6KzZLln1xtVv',
  placeholder:'...',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'mp'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>